{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Main idea of this project is to successfully classify intel landscape image dataset. This dataset consists of 6 different landscapes namely; **buildings, streets, glaciers, forests, deserts and XX** and I'm going to use **Convolutional Neural Networks (ConvNets)** machine learning method to classify these images **as fast as and as accurate as possible.**\n",
    "\n",
    "Convolutional Neural Network is **special type of Artificial Neural Network (ANN)** structure.\n",
    "What separates Convolutional Neural Networks from Artificial Neural Networks is state of art structure of **ConvNets that is specifically created for image classification and related tasks.** Unlike ANN's fully connected network structure, **Cluster of Convolutional Layers is the core of ConvNets.** and it is the main engine to squeeze the images into processable size and structure. Not surprisingly, this unique structure boosts computational capability of ConvNets during image classification tasks when it compared to ANN.\n",
    "\n",
    "\n",
    "* **Dataset**: Intel image dataset includes 6 different landscape images with 150x150 size.\n",
    "\n",
    "\n",
    "* **Inspiration**: Accurately classify as much as image possible with robust machine learning.\n",
    "\n",
    "\n",
    "* **Problem Definition**: Building Convolutional Neural Network model to obtain high accuracy.\n",
    "\n",
    "\n",
    "* **Link**: https://www.kaggle.com/puneet6060/intel-image-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "* **0.Explanatory Data Analysis**: Understanding the dataset and check class imbalance.\n",
    "\n",
    "\n",
    "* **Convolutional Neural Network**: Creating **ConvNets model** for the problem.\n",
    "\n",
    "\n",
    "* **Hyperparameter Tuning**: Optimizing **hyperparameters** of the ConvNets model to achieve better results.\n",
    "\n",
    "## Models\n",
    "* **ConvNets**:  Variants of ConvNets models.\n",
    "\n",
    "\n",
    "**Note:** Basically, I benefit from Kaggle GPU unit on this project to be able to obtain more robust results, therefore I did not run this code on Jupyter notebook but kaggle kernel section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and packages\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2  \n",
    "import keras\n",
    "import tensorflow.keras.layers as Layers\n",
    "import tensorflow.keras.models as Models\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow.keras.metrics as Metrics\n",
    "from keras.layers import Dropout\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sn\n",
    "import timeit\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import SGD\n",
    "from random import randint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "TRAIN_PATH = \"../input/seg_train/seg_train/\"\n",
    "TEST_PATH = \"../input/seg_test/seg_test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's **discover image categories** by their percentage distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis\n",
    "def explore_categories(path):\n",
    "    \"\"\"This function explores data folders and counts number of landscape category by category.\"\"\"\n",
    "\n",
    "    # Counting each iamge category\n",
    "    for category in os.listdir(path):\n",
    "        if(category == \"buildings\"):\n",
    "            no_buildings = len(os.listdir(path + \"/\" + \"buildings\"))\n",
    "        elif(category == \"forest\"):\n",
    "            no_forest = len(os.listdir(path + \"/\" + \"forest\"))\n",
    "        elif(category == \"glacier\"):\n",
    "            no_glacier = len(os.listdir(path + \"/\" + \"glacier\"))  \n",
    "        elif(category == \"mountain\"):\n",
    "            no_mountain = len(os.listdir(path + \"/\" + \"mountain\"))\n",
    "        elif(category == \"sea\"):\n",
    "            no_sea = len(os.listdir(path + \"/\" + \"sea\"))   \n",
    "        elif(category == \"street\"):\n",
    "            no_street = len(os.listdir(path + \"/\" + \"street\"))\n",
    "\n",
    "    # Summing all images.        \n",
    "    total_images = no_buildings + no_forest + no_glacier + no_mountain + no_sea + no_street\n",
    "\n",
    "    # Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "    labels = 'Buildings', 'Forest', 'Glacier', 'Mountain', 'Sea', 'Street'\n",
    "    percentages = [no_buildings/total_images, no_forest/total_images, no_glacier/total_images, no_mountain/total_images, no_sea/total_images, no_street/total_images]\n",
    "\n",
    "    if(path == TEST_PATH):\n",
    "        pie_chart_generate(percentages, labels, \"Test Data\")\n",
    "    elif(path == TRAIN_PATH):\n",
    "        pie_chart_generate(percentages, labels, \"Training Data\")\n",
    "    return total_images\n",
    "\n",
    "\n",
    "def pie_chart_generate(percentages, labels, title):\n",
    "  \"\"\"This function generates pie charts of given class labels.\"\"\"\n",
    "    # Defining color map for pie chart.\n",
    "    cmap = plt.get_cmap(\"tab20c\")\n",
    "    outer_colors = inner_colors = cmap(np.array([1, 2, 5, 6, 9, 10]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    ax.pie(percentages, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90, colors=outer_colors)\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Training data pie chart\n",
    "number_training_images = explore_categories(TRAIN_PATH)\n",
    "# Testing data pie chart\n",
    "number_testing_images = explore_categories(TEST_PATH)\n",
    "\n",
    "# Pie chart of the ratio of training and testing data\n",
    "training_testing_ratio = [number_training_images/(number_training_images + number_testing_images), number_testing_images/(number_training_images + number_testing_images)]\n",
    "pie_chart_generate(training_testing_ratio, ['Training Data', 'Test data'], 'Training-Test Ratio')\n",
    "\n",
    "print(\"Number of training images: \" + str(number_training_images))\n",
    "print(\"Number of testing images: \" + str(number_testing_images))\n",
    "print(\"Number of images for prediction: \" + str(len(os.listdir(\"../input/seg_pred/seg_pred/\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/pie1.png)\n",
    "![title](images/pie2.png)\n",
    "![title](images/pie3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, clearly there is **no class imbalance on both training and test images** so it is good news. Also we can see that we have **high amount of training images** and low amount of test images so that I need to be careful with **overfitting of the model.**\n",
    "\n",
    "Next, let's load the data from paths that I defined and shuffle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process data\n",
    "def pre_process(path, image_size=100):\n",
    "    \"\"\"This function loads, resizes, standardizes and shuffles all images.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in os.listdir(path):\n",
    "        if(category == \"buildings\"):\n",
    "            label = 0\n",
    "        elif(category == \"forest\"):\n",
    "            label = 1\n",
    "        elif(category == \"glacier\"):\n",
    "            label = 2  \n",
    "        elif(category == \"mountain\"):\n",
    "            label = 3  \n",
    "        elif(category == \"sea\"):\n",
    "            label = 4   \n",
    "        elif(category == \"street\"):\n",
    "            label = 5\n",
    "\n",
    "        training_subfolder_path = path + \"/\" + category\n",
    "\n",
    "        for file in os.listdir(training_subfolder_path):\n",
    "            image_path = training_subfolder_path + \"/\" + file\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            #Resize all images so they all have the same size\n",
    "            image = cv2.resize(image,(image_size, image_size))\n",
    "            image = np.array(image)\n",
    "\n",
    "            #Standardize data by dividing by 255\n",
    "            image = image.astype('float32')/255.0\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "    #Shuffle data\n",
    "    data, labels = shuffle(data, labels)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_data, labels = pre_process(TRAIN_PATH, image_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign class labels to each image and plot some of them to check the assign labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classlabel(class_code):\n",
    "  \"\"\"This function assign class label text on every image according  to their type.\"\"\"\n",
    "    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}  \n",
    "    return labels[class_code]\n",
    "# Plotting images with class labels.\n",
    "f,ax = plt.subplots(3,3)\n",
    "f.subplots_adjust(0,0,3,3)\n",
    "for i in range(0,3,1):\n",
    "    for j in range(0,3,1):\n",
    "        rnd_number = randint(0,len(train_data))\n",
    "        ax[i,j].imshow(train_data[rnd_number])\n",
    "        ax[i,j].set_title(get_classlabel(labels[rnd_number]))\n",
    "        ax[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/cl_images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's start to build our first Convolutional Neural Network. Before constructing the model, I would like to introduce core elements of ConvNets structure.\n",
    "* **Convolutional Layer:** **Fundamental component** of ConvNets. These layers are responsible for **filtering given input image and capturing certain features** of the image via applying filter operation. Essentially, Conv Layers' role is filtering useful information from given input image.\n",
    "\n",
    "![image-center](images/cnn.gif)\n",
    "\n",
    "* **Pooling Layers :** These layers are responsible for **reducing the number of parameters** of feature map that we obtained after convolutional layer. They function as **iterating specific kernel over feature map** to **apply function** on the map. Although there are different **types** such as **Max, Average and Sum pooling,** I used **Max Pooling** in which kernel iterates over rectified feature map and **takes largest elements of zone** that kernel applies its function.\n",
    "\n",
    "![image-center](images/max_pool.gif)\n",
    "\n",
    "\n",
    "* **Activation Functions:** They introduces **non-linearity** into neural network structure. Their role is to **transform input signal of a node into output signal.** Introducing non-linearity into NN structure is **crucial to be able to induce learning of complex non-linear relation of input and output.** Most common activation functions are **Sigmoid** (Logistic), **Tanh** (Hyperbolic Tangent) and **ReLu** (Rectified Linear Units).\n",
    "\n",
    "![image-center](images/acv_fun2.png)\n",
    "\n",
    "* **Dropout:** Simply this **layer dropouts some of the nodes (units)** within neural network structure with **certain probability** while **forward and backward propagation.** Dropout layer is essentially included within model to **avoid overfitting** because **deeply connected and inter-dependent nodes naturally cause overfitting** through each training state.\n",
    "\n",
    "![image-center](images/dropout.png)\n",
    "\n",
    "Dropout image: Srivastava, Nitish, et al. ”Dropout: a simple way to prevent neural networks from overfitting”, JMLR 2014\n",
    "\n",
    "* **Adam Optimizer:** Adam optimizer is one of the **most popular optimization method** being used training deep neural networks. Fundamentally, it is combination of **RMSprop and Stochastic Gradient Descend  with momentum.** It is **adaptive learning rate method** in which **individual learning rates** are computed for different parameters. It leverages first and second moments of gradient computations and use them to adapt the learning rate.\n",
    "\n",
    "\n",
    "According to discussed structure ConvNets, I create below neural network to train my model and conduct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing Convolutional Neural Network Model\n",
    "def cnn_model():\n",
    "    \"\"\"First Convolutional Nueral Network Model\"\"\"\n",
    "    model = Models.Sequential()\n",
    "\n",
    "    model.add(Layers.Conv2D(128,kernel_size=(3,3),activation='relu',input_shape=(100,100,3)))\n",
    "    model.add(Layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "    model.add(Layers.MaxPool2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Layers.Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "    model.add(Layers.Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "    model.add(Layers.MaxPool2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Layers.Flatten())\n",
    "    model.add(Layers.Dense(256,activation='relu'))\n",
    "    model.add(Layers.Dropout(0.5))\n",
    "\n",
    "    model.add(Layers.Dense(256,activation='relu'))\n",
    "    model.add(Layers.Dropout(0.5))\n",
    "\n",
    "    model.add(Layers.Dense(6,activation='softmax'))\n",
    "    model.compile(optimizer=Optimizer.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False),\n",
    "                  loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. I constructed my Convolutional Neural Network structure with Adam optimizer and proper learning rate. Next, I define model fit function to\n",
    "fit the neural network and make prediction. The function also plots accuracy and loss outcomes along with confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define model fit function.\n",
    "def model_fit(my_model, number_epochs, batch_size):\n",
    "    \"\"\"This function accepts neural network structure, number of epochs and bathc size as function parameters and train the neural network.\"\"\"\n",
    "    start_time = timeit.default_timer()\n",
    "    # Fit model\n",
    "    model= my_model\n",
    "    trained = model.fit(train_data,labels,epochs=number_epochs,validation_split=0.25,batch_size=batch_size)\n",
    "    elapsed = timeit.default_timer()\n",
    "    print('Runtime:', elapsed)\n",
    "\n",
    "    # Plotting accuracy and validation accuracy.\n",
    "    plt.plot(trained.history['acc'])\n",
    "    plt.plot(trained.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting loss and validation loss.\n",
    "    plt.plot(trained.history['loss'])\n",
    "    plt.plot(trained.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Prediction on test set.\n",
    "    test_images,test_labels = load_data('../input/seg_test/seg_test/')\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "    model.evaluate(test_images,test_labels, verbose=1)\n",
    "\n",
    "    # Plotting Confusion Matrix.\n",
    "    predictions = model.predict(test_images)\n",
    "    pred_labels = np.argmax(predictions, axis = 1)\n",
    "    frame={'y':test_labels,'y_predicted':pred_labels}\n",
    "    df = pd.DataFrame(frame, columns=['y','y_predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['y'], df['y_predicted'],rownames=['True Label'], colnames=['Predicted Label'], margins = False)\n",
    "    sn.heatmap(confusion_matrix,annot=True,fmt=\"d\",cmap=\"Blues\",linecolor=\"blue\", vmin=0,vmax=500)\n",
    "    plt.title('Confusion Matrix', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run first prediction with defined neural network. I run my model for 15 epochs with 32 batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Prediction\n",
    "model=cnn_model()\n",
    "number_epochs=15\n",
    "batch_size=32\n",
    "model_fit(model, number_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model Summary\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_40 (Conv2D)           (None, 98, 98, 128)       3584      \n",
    "_________________________________________________________________\n",
    "conv2d_41 (Conv2D)           (None, 96, 96, 128)       147584    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_16 (MaxPooling (None, 32, 32, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_42 (Conv2D)           (None, 30, 30, 256)       295168    \n",
    "_________________________________________________________________\n",
    "conv2d_43 (Conv2D)           (None, 28, 28, 256)       590080    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         \n",
    "_________________________________________________________________\n",
    "flatten_9 (Flatten)          (None, 20736)             0         \n",
    "_________________________________________________________________\n",
    "dense_26 (Dense)             (None, 256)               5308672   \n",
    "_________________________________________________________________\n",
    "dropout_17 (Dropout)         (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_27 (Dense)             (None, 256)               65792     \n",
    "_________________________________________________________________\n",
    "dropout_18 (Dropout)         (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_28 (Dense)             (None, 6)                 1542      \n",
    "=================================================================\n",
    "Total params: 6,412,422\n",
    "Trainable params: 6,412,422\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we have **10525 training image and 3509 validation image.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 10525 samples, validate on 3509 samples\n",
    "Epoch 1/15\n",
    "10525/10525 [==============================] - 17s 2ms/sample - loss: 1.2295 - acc: 0.4968 - val_loss: 0.9556 - val_acc: 0.6022\n",
    "Epoch 2/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.9637 - acc: 0.6113 - val_loss: 0.8318 - val_acc: 0.6566\n",
    "Epoch 3/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.8167 - acc: 0.6862 - val_loss: 0.7628 - val_acc: 0.7244\n",
    "Epoch 4/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.7039 - acc: 0.7385 - val_loss: 0.5879 - val_acc: 0.7885\n",
    "Epoch 5/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.6204 - acc: 0.7769 - val_loss: 0.5494 - val_acc: 0.8054\n",
    "Epoch 6/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.5450 - acc: 0.8058 - val_loss: 0.5359 - val_acc: 0.8119\n",
    "[==============================]\n",
    "Epoch 13/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.1996 - acc: 0.9286 - val_loss: 0.8162 - val_acc: 0.7903\n",
    "Epoch 14/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.1849 - acc: 0.9376 - val_loss: 0.7688 - val_acc: 0.8176\n",
    "Epoch 15/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 0.1574 - acc: 0.9457 - val_loss: 0.7745 - val_acc: 0.8145\n",
    "Runtime: 108304.077418699"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze model outcomes. **Clearly**, my model starts to **overfitting from 5th Epoch** as train and test lines **cross** each other and **builds separation** through following epochs. Therefore, it is easy to observe that model is **overfitting to training set** and it has poor performance on validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/m1_acc.png)\n",
    "![title](images/m1_loss.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3000/3000 [==============================] - 2s 508us/sample - loss: 0.7719 - acc: 0.8067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I obtain **%80 accuracy from first prediction.** As a baseline score, it is not bad but requires improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](images/cm_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From confusion matrix, one can observe that model **performs poorly** on recognizing **Building images** (Label 0) and mountain image (label 3). It misclassifies **mountains as glaciers** and **buildings as streets** or vice versa.\n",
    "\n",
    "As next step, let's increase the batch size to boost batch of images that being trained in each step. I **increase batch size from 32 to 128.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Prediction\n",
    "model=cnn_model()\n",
    "number_epochs=15\n",
    "batch_size=128\n",
    "model_fit(model, number_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, I did not change structure of my model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 10525 samples, validate on 3509 samples\n",
    "Epoch 1/15\n",
    "10525/10525 [==============================] - 15s 1ms/sample - loss: 1.3919 - acc: 0.4217 - val_loss: 1.0312 - val_acc: 0.5919\n",
    "Epoch 2/15\n",
    "10525/10525 [==============================] - 14s 1ms/sample - loss: 1.0348 - acc: 0.5850 - val_loss: 0.8856 - val_acc: 0.6669\n",
    "Epoch 3/15\n",
    "10525/10525 [==============================] - 14s 1ms/sample - loss: 0.9198 - acc: 0.6383 - val_loss: 0.7974 - val_acc: 0.6948\n",
    "[==============================]\n",
    "Epoch 13/15\n",
    "10525/10525 [==============================] - 14s 1ms/sample - loss: 0.2715 - acc: 0.9031 - val_loss: 0.5515 - val_acc: 0.8290\n",
    "Epoch 14/15\n",
    "10525/10525 [==============================] - 14s 1ms/sample - loss: 0.2365 - acc: 0.9158 - val_loss: 0.5132 - val_acc: 0.8521\n",
    "Epoch 15/15\n",
    "10525/10525 [==============================] - 13s 1ms/sample - loss: 0.2051 - acc: 0.9269 - val_loss: 0.5623 - val_acc: 0.8487\n",
    "Runtime: 108832.818498101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/m2_acc.png)\n",
    "![title](images/m2_loss.png)\n",
    "Alright, **overfitting** problem is **still evident** fact from 7th Epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3000/3000 [==============================] - 2s 504us/sample - loss: 0.5735 - acc: 0.8433\n",
    "\n",
    "Yet, model manages to decrease **loss from 0.77 to 0.57** and to **increase accuracy almost %4.** This is great!. Now, the model correctly **classifies %84 of images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/cm_2.png)\n",
    "\n",
    "Reflection of model accuracy increase can be observed from confusion matrix as well. Number of correct classification of building (label 0) and mountain (label 3) increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Augmentation**\n",
    "\n",
    "As I am looking forward **to increase my model accuracy,** I start applying **Data Augmentation** to increase my training and validation data. Data Augmentation is a method to increase available dataset by altering image specification of existing image. **Alteration** may involve:\n",
    "* Horizontal or vertical flip,\n",
    "* Gamma adjustment,\n",
    "* Rotation of image,\n",
    "* Adding Gaussian noise,\n",
    "* Cropping, zooming and stretching.\n",
    "\n",
    "In my model, I only benefit from flipping images horizontally and vertically. I observed **decrease on accuracy** when I applied **gamma adjustment, zooming and sheering.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Augmentation Section\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage.exposure import adjust_gamma\n",
    "\n",
    "#Defining augmentation operations.\n",
    "def horizontal_flip(image):\n",
    "    \"\"\"Flips the given image horizontally\"\"\"\n",
    "    return image[:, ::-1]\n",
    "\n",
    "def up_side_down(image):\n",
    "    return np.rot90(image, 2)\n",
    "\n",
    "# Defining augmentation methods.    \n",
    "methods={'h_flip':horizontal_flip,'u_s_d':up_side_down}\n",
    "# Defining data and label lists to append images into.\n",
    "data = []\n",
    "labels = []\n",
    "# Setting the path of data.\n",
    "path = \"../input/seg_train/seg_train/\"\n",
    "for category in os.listdir(path):\n",
    "    if(category == \"buildings\"):\n",
    "        label = 0\n",
    "    elif(category == \"forest\"):\n",
    "        label = 1\n",
    "    elif(category == \"glacier\"):\n",
    "        label = 2  \n",
    "    elif(category == \"mountain\"):\n",
    "        label = 3  \n",
    "    elif(category == \"sea\"):\n",
    "        label = 4   \n",
    "    elif(category == \"street\"):\n",
    "        label = 5\n",
    "\n",
    "    training_subfolder_path = path + \"/\" + category        \n",
    "    for file in os.listdir(training_subfolder_path):\n",
    "        image_path = training_subfolder_path + \"/\" + file\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        #Resize all images so they all have the same size\n",
    "        image = cv2.resize(image,(100,100))\n",
    "        image = np.array(image)\n",
    "\n",
    "        #Standardize data by dividing by 255\n",
    "        image = image.astype('float32')/255.0\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "        # Randomly choosing an augmentation operation.\n",
    "        key = random.choice(list(methods))\n",
    "        image=methods[key](image)\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "# Generating training dataset.\n",
    "print(\"Training data\", len(data))\n",
    "\n",
    "#Shuffle data\n",
    "data, labels = shuffle(data, labels)\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "train_data=data\n",
    "\n",
    "Training data 28068"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data augmentation process, I doubled my training data amount **from 14k to 28k images.** Let's try my model with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Prediction\n",
    "model=cnn_model()\n",
    "number_epochs=20\n",
    "batch_size=128\n",
    "model_fit(model, number_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 21051 samples, validate on 7017 samples\n",
    "Epoch 1/20\n",
    "21051/21051 [==============================] - 28s 1ms/sample - loss: 1.2831 - acc: 0.4487 - val_loss: 1.0145 - val_acc: 0.5780\n",
    "Epoch 2/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.9501 - acc: 0.5951 - val_loss: 0.7999 - val_acc: 0.6697\n",
    "Epoch 3/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.7789 - acc: 0.6966 - val_loss: 0.6473 - val_acc: 0.7525\n",
    "Epoch 4/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.6329 - acc: 0.7665 - val_loss: 0.6178 - val_acc: 0.7723\n",
    "Epoch 5/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.5546 - acc: 0.8006 - val_loss: 0.4871 - val_acc: 0.8236\n",
    "[==============================]\n",
    "Epoch 18/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.1836 - acc: 0.9368 - val_loss: 0.5725 - val_acc: 0.8465\n",
    "Epoch 19/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.1415 - acc: 0.9489 - val_loss: 0.6176 - val_acc: 0.8371\n",
    "Epoch 20/20\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.1182 - acc: 0.9572 - val_loss: 0.6233 - val_acc: 0.8427\n",
    "Runtime: 110212.927397731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting** problem is **still existing** in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/m3_acc.png)\n",
    "![title](images/m3_loss.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3000/3000 [==============================] - 2s 510us/sample - loss: 0.6710 - acc: 0.8473"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No substantial improvement** on model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/cm_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "def cnn_model2():\n",
    "    \"\"\"function description\"\"\"    \n",
    "    model = Models.Sequential()\n",
    "\n",
    "    model.add(Layers.Conv2D(128,kernel_size=(3,3),activation='relu',input_shape=(100,100,3)))\n",
    "    model.add(Layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "    model.add(Layers.MaxPool2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Layers.Conv2D(256,kernel_size=(3,3),activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Layers.Conv2D(256,kernel_size=(3,3),activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Layers.MaxPool2D(pool_size=(3,3)))\n",
    "\n",
    "    model.add(Layers.Flatten())\n",
    "    model.add(Layers.Dense(256,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Layers.Dropout(0.5))\n",
    "\n",
    "    model.add(Layers.Dense(256,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Layers.Dropout(0.5))\n",
    "\n",
    "    model.add(Layers.Dense(6,activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Optimizer.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=True),\n",
    "                  loss='sparse_categorical_crossentropy',metrics=['accuracy'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in the 2nd model I changed the **learning rate from 0.0001 to 0.001.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth Prediction\n",
    "model=cnn_model2()\n",
    "number_epochs=60\n",
    "batch_size=128\n",
    "\n",
    "model_fit(model, number_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 21051 samples, validate on 7017 samples\n",
    "Epoch 1/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 2.2126 - acc: 0.4135 - val_loss: 1.6589 - val_acc: 0.5766\n",
    "Epoch 2/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 1.6342 - acc: 0.5666 - val_loss: 1.4002 - val_acc: 0.6652\n",
    "Epoch 3/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 1.4150 - acc: 0.6361 - val_loss: 1.2477 - val_acc: 0.6957\n",
    "Epoch 4/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 1.2873 - acc: 0.6771 - val_loss: 1.1649 - val_acc: 0.7173\n",
    "Epoch 5/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 1.1817 - acc: 0.7067 - val_loss: 1.0590 - val_acc: 0.7532\n",
    "[==============================]\n",
    "Epoch 58/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.3583 - acc: 0.9519 - val_loss: 0.6932 - val_acc: 0.8551\n",
    "Epoch 59/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.3458 - acc: 0.9565 - val_loss: 0.6877 - val_acc: 0.8572\n",
    "Epoch 60/60\n",
    "21051/21051 [==============================] - 27s 1ms/sample - loss: 0.3387 - acc: 0.9587 - val_loss: 0.6541 - val_acc: 0.8689\n",
    "Runtime: 99478.285476088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/m4_acc.png)\n",
    "![title](images/m4_loss.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3000/3000 [==============================] - 1s 461us/sample - loss: 0.6773 - acc: 0.8687"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/cm_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "At the end of this project, I tried different approaches to be able to classify intel landscape image dataset as accurate as possible. I used **ConvNets** to tackle this problem. To **avoid overfitting** I utilized **L2 Regularization (Gaussian Prior/Ridge) along with dropout and data augmentation.**\n",
    "\n",
    "Finally, designed deep learning model is able to **classify landscape images with around %87 success rate.**\n",
    "\n",
    "As next step, one can change deep learning structure, making model deeper or shallower, including average or sum pooling approaches. In addition, one can also try out different optimizer such as Stochastic Gradient Descent or Adagrad with optimizing learning rate and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
